#!/usr/bin/env python
"""ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ - ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° í¬í•¨"""
import sys
import os
# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ pathì— ì¶”ê°€ (test_codeì˜ ìƒìœ„ì¸ dart-mcp ë””ë ‰í† ë¦¬)
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from workflow.dart_orchestrator import DartOrchestrator
from tools import dart_api_tools
import asyncio
import json
from datetime import datetime
from pathlib import Path
import csv

async def test_full_pipeline():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    import time
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = Path("test_logs")
    log_dir.mkdir(exist_ok=True)
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ë¡œê·¸ íŒŒì¼ ì´ë¦„ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"pipeline_test_{timestamp}.json"
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        # "ìµœê·¼ 1ë…„ ì£¼ì‹ë§¤ìˆ˜ì„ íƒê¶Œ ë¶€ì—¬ ê³µì‹œì— ëŒ€í•´ ìƒì„¸ ë‚´ìš©ì„ ì •ë¦¬í•´ì¤˜",
        "ìµœê·¼ 1ê°œì›” ìƒì¥íšŒì‚¬ì˜ ì¸ìˆ˜ í•©ë³‘ ê³µì‹œì—ì„œ í•©ë³‘ ë¹„ìœ¨ì€ ì–´ë• ëŠ”ì§€ ì°¾ì•„ë´ì¤˜.",
        # "í¬ë¼ìš°ë“œì›ìŠ¤ íƒ€ë²•ì¸ ì¦ê¶Œì–‘ìˆ˜ ê³µì‹œ ì°¾ì•„ì„œ ìš”ì•½í•´ì¤˜",
        # "2024ë…„ 3ë¶„ê¸° ì‹¤ì  ë°œí‘œ ê¸°ì—…ë“¤"
    ]
    
    dart = DartOrchestrator(dart_api_tools)
    
    # ìºì‹œ ìƒíƒœ í™•ì¸ ë° ì„ íƒì  í´ë¦¬ì–´
    print("ğŸ’¾ ìºì‹œ ì„¤ì •:")
    print(f"   Cache Type: {type(dart.document_fetcher.cache).__name__}")
    
    # ìºì‹œë¥¼ í´ë¦¬ì–´í•˜ê³  ì‹¶ìœ¼ë©´ ì£¼ì„ í•´ì œ
    await dart.document_fetcher.cache.clear()
    print("   ğŸ§¹ ìºì‹œ í´ë¦¬ì–´ë¨")
    
    # ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ìš©
    test_results = {
        "test_time": timestamp,
        "queries": []
    }
    
    for query in test_queries[:1]:  # ì²« ë²ˆì§¸ ì¿¼ë¦¬ë§Œ í…ŒìŠ¤íŠ¸
        print("=" * 60)
        print(f"ì¿¼ë¦¬: {query}")
        print("=" * 60)
        
        # í˜„ì¬ ì¿¼ë¦¬ ê²°ê³¼ ì €ì¥ìš©
        query_result = {
            "query": query,
            "start_time": datetime.now().isoformat(),
            "steps": {},
            "timing": {},
            "error": None
        }
        
        try:
            # ì‹œê°„ ì¸¡ì • ë³€ìˆ˜
            total_start = time.time()
            step_times = {}
            
            # 1. Query Expansion
            step_start = time.time()
            print("\nâ±ï¸ [1/5] Query Expansion ì‹œì‘...")
            expanded_query = await dart.query_expander.expand_query(query)
            step_times["query_expansion"] = time.time() - step_start
            print(f"   âœ“ ì™„ë£Œ ({step_times['query_expansion']:.2f}ì´ˆ)")
            print(f"   â†’ {dart.query_expander.format_result(expanded_query)[:200]}...")
            
            # Query Expansion ê²°ê³¼ ì €ì¥
            query_result["steps"]["query_expansion"] = {
                "duration": step_times["query_expansion"],
                "result": expanded_query
            }
            
            # 2. Search Execution (ì œí•œ ì—†ì´ ëª¨ë“  ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°)
            step_start = time.time()
            print("\nâ±ï¸ [2/5] Search Execution ì‹œì‘...")
            search_results = await dart._execute_searches(expanded_query, 999)  # ì‹¤ì§ˆì ìœ¼ë¡œ ì œí•œ ì—†ìŒ
            step_times["search"] = time.time() - step_start
            print(f"   âœ“ ì™„ë£Œ ({step_times['search']:.2f}ì´ˆ)")
            print(f"   â†’ {len(search_results)}ê±´ ê²€ìƒ‰ë¨")
            
            # Search ê²°ê³¼ ì €ì¥ (ë©”íƒ€ë°ì´í„°ë§Œ)
            query_result["steps"]["search"] = {
                "duration": step_times["search"],
                "total_results": len(search_results),
                "results": [
                    {
                        "rcept_no": r.get("rcept_no") or r.get("rcp_no"),
                        "corp_name": r.get("corp_name"),
                        "report_nm": r.get("report_nm"),
                        "rcept_dt": r.get("rcept_dt")
                    }
                    for r in search_results
                ]
            }
            
            # 3. Document Filtering
            step_start = time.time()
            print("\nâ±ï¸ [3/5] Document Filtering ì‹œì‘...")
            filtered_results = await dart.document_filter.filter_documents(query, search_results, expanded_query)
            step_times["document_filtering"] = time.time() - step_start
            print(f"   âœ“ ì™„ë£Œ ({step_times['document_filtering']:.2f}ì´ˆ)")
            print(f"   â†’ {len(search_results)}ê±´ ì¤‘ {len(filtered_results)}ê±´ í•„í„°ë§ë¨")
            
            # Document Filtering ê²°ê³¼ ì €ì¥
            query_result["steps"]["document_filtering"] = {
                "duration": step_times["document_filtering"],
                "total_input": len(search_results),
                "total_filtered": len(filtered_results),
                "filtering_ratio": len(filtered_results) / len(search_results) if search_results else 0,
                "filtered_documents": [
                    {
                        "rcept_no": d.get("rcept_no"),
                        "corp_name": d.get("corp_name"),
                        "report_nm": d.get("report_nm"),
                        "rcept_dt": d.get("rcept_dt"),
                        "relevance_score": d.get("relevance_score", 0)
                    }
                    for d in filtered_results
                ]
            }
            
            # 4. Document Processing (í•„í„°ë§ëœ ë¬¸ì„œë§Œ ì²˜ë¦¬)
            step_start = time.time()
            print("\nâ±ï¸ [4/5] Document Processing ì‹œì‘...")
            processed_docs = await dart._process_documents(filtered_results, expanded_query)
            step_times["document_processing"] = time.time() - step_start
            print(f"   âœ“ ì™„ë£Œ ({step_times['document_processing']:.2f}ì´ˆ)")
            print(f"   â†’ {len(processed_docs)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ")
            
            content_count = 0
            if processed_docs:
                content_count = sum(1 for d in processed_docs if d.get('content'))
                print(f"   â†’ ë‚´ìš© í¬í•¨ ë¬¸ì„œ: {content_count}ê°œ")
            
            # Document Processing ê²°ê³¼ ì €ì¥
            query_result["steps"]["document_processing"] = {
                "duration": step_times["document_processing"],
                "total_processed": len(processed_docs),
                "content_fetched": content_count,
                "documents": [
                    {
                        "rcept_no": d.get("rcept_no"),
                        "corp_name": d.get("corp_name"),
                        "report_nm": d.get("report_nm"),
                        "has_content": bool(d.get("content")),
                        "content_length": len(d.get("content", "")) if d.get("content") else 0,
                        "source": d.get("source"),
                        "relevance_score": d.get("relevance_score", 0)
                    }
                    for d in processed_docs
                ]
            }
            
            # 5. Synthesis
            step_start = time.time()
            print("\nâ±ï¸ [5/5] Synthesis ì‹œì‘...")
            synthesis_result = await dart.synthesizer.synthesize(
                query, processed_docs, expanded_query,
                {
                    "total_searched": len(search_results),
                    "total_filtered": len(filtered_results),
                    "total_processed": len(processed_docs)
                }
            )
            step_times["synthesis"] = time.time() - step_start
            print(f"   âœ“ ì™„ë£Œ ({step_times['synthesis']:.2f}ì´ˆ)")
            
            # Synthesis ê²°ê³¼ ì €ì¥
            query_result["steps"]["synthesis"] = {
                "duration": step_times["synthesis"],
                "result": synthesis_result
            }
            
            # ì „ì²´ ì‹œê°„
            total_time = time.time() - total_start
            
            # íƒ€ì´ë° ì •ë³´ ì €ì¥
            query_result["timing"] = step_times
            query_result["total_time"] = total_time
            query_result["end_time"] = datetime.now().isoformat()
            
            # ì‹œê°„ ìš”ì•½
            print("\n" + "=" * 50)
            print("â° ì†Œìš”ì‹œê°„ ìš”ì•½")
            print("=" * 50)
            for step_name, step_time in step_times.items():
                percent = (step_time / total_time) * 100
                bar = "â–ˆ" * int(percent / 2)
                print(f"{step_name:20s}: {step_time:5.2f}ì´ˆ ({percent:5.1f}%) {bar}")
            print("-" * 50)
            print(f"{'ì „ì²´':20s}: {total_time:5.2f}ì´ˆ")
            
            # ê²°ê³¼ JSONìœ¼ë¡œ ë³€í™˜
            result_json = json.dumps(synthesis_result, ensure_ascii=False, indent=2)
            
            # ê²°ê³¼ íŒŒì‹±
            result = json.loads(result_json)
            
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            if result.get("status") == "error":
                print(f"âŒ ì—ëŸ¬: {result.get('error')}")
            else:
                print("\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:")
                if "summary" in result:
                    summary = result["summary"]
                    print(f"  - ì´ ë¬¸ì„œ ìˆ˜: {summary.get('total_documents', 0)}")
                    print(f"  - ê¸°ê°„: {summary.get('date_range', {})}")
                    print(f"  - ê¸°ì—…: {', '.join(summary.get('companies', []))}")
                
                # í•„í„°ë§ í†µê³„ ì¶”ê°€
                print(f"\nğŸ“ˆ ì²˜ë¦¬ í†µê³„:")
                print(f"  - ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(search_results)}ê±´")
                print(f"  - í•„í„°ë§ëœ ë¬¸ì„œ: {len(filtered_results)}ê±´")
                print(f"  - ì²˜ë¦¬ëœ ë¬¸ì„œ: {len(processed_docs)}ê±´")
                print(f"  - ë‚´ìš© ê°€ì ¸ì˜¨ ë¬¸ì„œ: {content_count}ê±´")
                
                print("\nğŸ“ LLM ë‹µë³€:")
                if "answer" in result:
                    answer = result["answer"]
                    # ê¸´ ë‹µë³€ì€ ì¤„ì—¬ì„œ í‘œì‹œ
                    if len(answer) > 500:
                        print(f"  {answer[:500]}...")
                    else:
                        print(f"  {answer}")
                
                print("\nğŸ“„ ìƒìœ„ ë¬¸ì„œë“¤:")
                if "documents" in result:
                    for i, doc in enumerate(result["documents"][:3], 1):
                        print(f"\n  [{i}] {doc.get('company', 'N/A')} - {doc.get('title', 'N/A')}")
                        print(f"      ë‚ ì§œ: {doc.get('date', 'N/A')}")
                        print(f"      ì ‘ìˆ˜ë²ˆí˜¸: {doc.get('rcept_no', 'N/A')}")
                        
                        # ë¬¸ì„œ ë‚´ìš© ì†ŒìŠ¤ í™•ì¸
                        if doc.get("source"):
                            print(f"      ì†ŒìŠ¤: {doc['source']}")
                        
                        # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                        if doc.get("content"):
                            content_preview = doc["content"][:200] if doc["content"] else "ë‚´ìš© ì—†ìŒ"
                            print(f"      ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {content_preview}...")
                        elif doc.get("structured_data"):
                            print(f"      êµ¬ì¡°í™”ëœ ë°ì´í„° í¬í•¨")
                        else:
                            print(f"      ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨")
                
                print("\nğŸ”‘ í•µì‹¬ ì •ë³´:")
                if "key_findings" in result:
                    for finding in result["key_findings"][:3]:
                        print(f"  â€¢ {finding}")
            
        except Exception as e:
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            
            # ì—ëŸ¬ ì •ë³´ ì €ì¥
            query_result["error"] = {
                "message": str(e),
                "type": type(e).__name__,
                "traceback": traceback.format_exc()
            }
        
        # ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ì „ì²´ ê²°ê³¼ì— ì¶”ê°€
        test_results["queries"].append(query_result)
        
        # ê° ì¿¼ë¦¬ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(test_results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {log_file}")
        
        print("\n" + "=" * 60)
    
    # ìµœì¢… ìš”ì•½ ì •ë³´ ì¶”ê°€
    test_results["summary"] = {
        "total_queries": len(test_results["queries"]),
        "successful": sum(1 for q in test_results["queries"] if not q.get("error")),
        "failed": sum(1 for q in test_results["queries"] if q.get("error")),
        "total_documents_processed": sum(
            q.get("steps", {}).get("document_processing", {}).get("total_processed", 0)
            for q in test_results["queries"]
        ),
        "total_documents_with_content": sum(
            q.get("steps", {}).get("document_processing", {}).get("content_fetched", 0)
            for q in test_results["queries"]
        )
    }
    
    # ìµœì¢… ì €ì¥
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(test_results, f, ensure_ascii=False, indent=2)
    
    # CSV íŒŒì¼ë¡œë„ ì €ì¥ (ê°„ë‹¨í•œ ìš”ì•½)
    csv_file = log_dir / f"pipeline_summary_{timestamp}.csv"
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['Query', 'Total Time', 'Search Results', 'Filtered Results', 
                        'Documents Processed', 'Documents with Content', 'Status'])
        
        for q in test_results["queries"]:
            writer.writerow([
                q["query"][:50],  # ì¿¼ë¦¬ (ìµœëŒ€ 50ì)
                f"{q.get('total_time', 0):.2f}",
                q.get("steps", {}).get("search", {}).get("total_results", 0),
                q.get("steps", {}).get("document_filtering", {}).get("total_filtered", 0),
                q.get("steps", {}).get("document_processing", {}).get("total_processed", 0),
                q.get("steps", {}).get("document_processing", {}).get("content_fetched", 0),
                "ERROR" if q.get("error") else "SUCCESS"
            ])
    
    print(f"\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
    print(f"   - JSON: {log_file}")
    print(f"   - CSV: {csv_file}")

async def test_document_fetcher():
    """ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° ëª¨ë“ˆ ë‹¨ë… í…ŒìŠ¤íŠ¸"""
    from workflow.utils.document_fetcher import DocumentFetcherV2
    
    print("\n" + "=" * 60)
    print("ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    fetcher = DocumentFetcherV2(dart_api_tools)
    
    # í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œ ì •ë³´
    test_doc = {
        "rcept_no": "20240101000001",  # ì˜ˆì‹œ ì ‘ìˆ˜ë²ˆí˜¸
        "corp_code": "00126380",  # ì‚¼ì„±ì „ì ì½”ë“œ
        "corp_name": "ì‚¼ì„±ì „ì",
        "report_nm": "ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œ(ìê¸°ì£¼ì‹ì·¨ë“ê²°ì •)",
        "report_type": "B001"
    }
    
    print(f"í…ŒìŠ¤íŠ¸ ë¬¸ì„œ: {test_doc['corp_name']} - {test_doc['report_nm']}")
    
    # ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
    result = await fetcher.fetch_document_content(
        rcept_no=test_doc["rcept_no"],
        corp_code=test_doc["corp_code"],
        report_type=test_doc["report_type"],
        fetch_mode="auto"
    )
    
    if result.get("error"):
        print(f"âŒ ì—ëŸ¬: {result['error']}")
    else:
        print(f"âœ… ì†ŒìŠ¤: {result.get('source', 'unknown')}")
        
        if result.get("structured_data"):
            print("âœ… êµ¬ì¡°í™”ëœ ë°ì´í„° íšë“")
            for key in result["structured_data"].keys():
                print(f"  - {key}")
        
        if result.get("content"):
            print(f"âœ… ë‚´ìš© ê¸¸ì´: {len(result['content'])} ê¸€ì")
            print(f"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n{result['content'][:300]}...")

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ DART íŒŒì´í”„ë¼ì¸ ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    # ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    # await test_document_fetcher()
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    await test_full_pipeline()
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    asyncio.run(main())