"""
ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (ê°œì„ ëœ ë²„ì „)
DART APIì˜ êµ¬ì¡°ì— ë§ê²Œ ë¬¸ì„œ ìƒì„¸ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ëª¨ë“ˆ
"""

import asyncio
import json
from typing import Dict, Any, List, Optional, Tuple
from utils.logging import get_logger
from utils.cache import cached, get_cache
from utils.content_cleaner import clean_content, clean_for_llm

logger = get_logger("document_fetcher_v2")

# ë¬¸ì„œ ìœ í˜•ë³„ ìƒì„¸ API ë§¤í•‘
DETAILED_API_MAPPING = {
    # ì •ê¸°ë³´ê³ ì„œ (Aë¡œ ì‹œì‘)
    "A001": "periodic_report",  # ì‚¬ì—…ë³´ê³ ì„œ
    "A002": "periodic_report",  # ë°˜ê¸°ë³´ê³ ì„œ  
    "A003": "periodic_report",  # ë¶„ê¸°ë³´ê³ ì„œ
    
    # ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œ (Bë¡œ ì‹œì‘)
    "B001": "major_report",  # ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œ
    "B002": "major_report",  # ì£¼ìš”ê²½ì˜ì‚¬í•­
    "B003": "major_report",  # ìµœëŒ€ì£¼ì£¼ë“±ê³¼ì˜ê±°ë˜
    
    # ì¦ê¶Œì‹ ê³ ì„œ (Cë¡œ ì‹œì‘)
    "C001": "securities_registration",  # ì¦ê¶Œì‹ ê³ (ì§€ë¶„ì¦ê¶Œ)
    "C002": "securities_registration",  # ì¦ê¶Œì‹ ê³ (ì±„ë¬´ì¦ê¶Œ)
    "C003": "securities_registration",  # ì¦ê¶Œì‹ ê³ (íŒŒìƒê²°í•©ì¦ê¶Œ)
    
    # ì§€ë¶„ê³µì‹œ (Dë¡œ ì‹œì‘)
    "D001": "ownership_disclosure",  # ëŒ€ëŸ‰ë³´ìœ ìƒí™©ë³´ê³ ì„œ
    "D002": "ownership_disclosure",  # ì„ì›ì£¼ìš”ì£¼ì£¼ë³´ê³ ì„œ
    "D003": "ownership_disclosure",  # ì˜ê²°ê¶ŒëŒ€ë¦¬í–‰ì‚¬
    "D004": "ownership_disclosure",  # ê³µê°œë§¤ìˆ˜
}


class DocumentFetcherV2:
    """DART ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (ê°œì„ ëœ ë²„ì „)"""
    
    def __init__(self, dart_api_tools):
        """
        Args:
            dart_api_tools: dart_api_tools ëª¨ë“ˆ
        """
        self.dart_api = dart_api_tools
        self.dart_reader = getattr(dart_api_tools, 'dart_reader', None)
        self.cache = get_cache()
        
    async def fetch_document_content(
        self,
        rcept_no: str,
        corp_code: str = None,
        report_type: str = None,
        fetch_mode: str = "auto",
        detailed_types: Dict[str, List[str]] = None
    ) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (ìƒì„¸ API ìš°ì„ , ì‹¤íŒ¨ì‹œ ì›ë³¸)
        
        Args:
            rcept_no: ì ‘ìˆ˜ë²ˆí˜¸
            corp_code: íšŒì‚¬ ê³ ìœ ë²ˆí˜¸ (ìƒì„¸ API ì‚¬ìš©ì‹œ í•„ìš”)
            report_type: ë³´ê³ ì„œ ìœ í˜• ì½”ë“œ (ex: B001, A001)
            fetch_mode: 
                - "auto": ìë™ ì„ íƒ (ìƒì„¸ API ì‹œë„ í›„ ì›ë³¸)
                - "detailed": ìƒì„¸ APIë§Œ ì‚¬ìš©
                - "original": ì›ë³¸ ë¬¸ì„œë§Œ ì‚¬ìš©
            detailed_types: ìƒì„¸ ë¬¸ì„œ íƒ€ì… ë”•ì…”ë„ˆë¦¬ (major_events, securities, business_reports)
                
        Returns:
            ë¬¸ì„œ ë‚´ìš© ë”•ì…”ë„ˆë¦¬
        """
        # ìºì‹œ í‚¤ ìƒì„±
        cache_params = {
            "rcept_no": rcept_no,
            "corp_code": corp_code,
            "report_type": report_type,
            "fetch_mode": fetch_mode
        }
        
        # ìºì‹œ í™•ì¸
        cached_result = await self.cache.get("fetch_document_content", cache_params)
        if cached_result is not None:
            logger.debug(f"Cache hit for document {rcept_no}")
            return cached_result
        
        try:
            logger.info(f"Fetching document {rcept_no} (mode: {fetch_mode}, type: {report_type}, corp: {corp_code})")
            
            result = {
                "rcept_no": rcept_no,
                "corp_code": corp_code,
                "report_type": report_type,
                "content": None,
                "structured_data": None,
                "source": None,
                "error": None
            }
            
            # 1. ë¬¸ì„œ ìœ í˜• í™•ì¸ ë° ìƒì„¸ API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨
            api_type = self._get_api_type(report_type)
            
            if fetch_mode in ["auto", "detailed"] and api_type and corp_code:
                # 2. ìƒì„¸ APIë¡œ êµ¬ì¡°í™”ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                print(corp_code, rcept_no, api_type, detailed_types)
                structured_data = await self._fetch_structured_data(
                    corp_code, rcept_no, api_type, detailed_types
                )
                
                if structured_data and isinstance(structured_data, dict) and not structured_data.get("error"):
                    result["structured_data"] = structured_data
                    result["content"] = self._extract_content_from_structured(structured_data)
                    result["source"] = "detailed_api"
                    logger.info(f"Successfully fetched structured data for {rcept_no}")
                    return result
                elif fetch_mode == "detailed":
                    # detailed ëª¨ë“œì—ì„œ ì‹¤íŒ¨ì‹œ ì—ëŸ¬ ë°˜í™˜
                    error_msg = "Failed to fetch detailed data"
                    if structured_data and isinstance(structured_data, dict):
                        error_msg = structured_data.get("error", error_msg)
                    result["error"] = error_msg
                    return result
            
            # 3. ì›ë³¸ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° (ìƒì„¸ API ì‹¤íŒ¨ ë˜ëŠ” ë¯¸ì§€ì›)
            if fetch_mode in ["auto", "original"]:
                original_content = await self._fetch_original_document(rcept_no)
                
                if original_content and not original_content.get("error"):
                    result["content"] = original_content.get("content")
                    result["source"] = "original_document"
                    logger.info(f"Successfully fetched original document for {rcept_no}")
                else:
                    result["error"] = original_content.get("error", "Failed to fetch original document")
            
            # ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì˜¨ ê²½ìš° ìºì‹œì— ì €ì¥
            if result and not result.get("error"):
                await self.cache.set("fetch_document_content", cache_params, result)
                logger.debug(f"Cached document content for {rcept_no}")
            
            return result
            
        except Exception as e:
            logger.error(f"Failed to fetch document {rcept_no}: {e}")
            return {
                "rcept_no": rcept_no,
                "content": None,
                "error": str(e)
            }
    
    def _get_api_type(self, report_type: str) -> Optional[str]:
        """ë³´ê³ ì„œ ìœ í˜•ì—ì„œ API íƒ€ì… ê²°ì •"""
        if not report_type:
            return None
            
        # ë¬¸ì„œ ì½”ë“œì˜ ì²« ê¸€ìë¡œ ëŒ€ëµì ì¸ ìœ í˜• íŒë‹¨
        if report_type.startswith("A"):
            return "periodic_report"
        elif report_type.startswith("B"):
            return "major_report"
        elif report_type.startswith("C"):
            return "securities_registration"
        elif report_type.startswith("D"):
            return "ownership_disclosure"
        
        # ì •í™•í•œ ë§¤í•‘ í™•ì¸
        return DETAILED_API_MAPPING.get(report_type)
    
    async def _fetch_structured_data(
        self,
        corp_code: str,
        rcept_no: str,
        api_type: str,
        detailed_types: Dict[str, List[str]] = None
    ) -> Optional[Dict[str, Any]]:
        """êµ¬ì¡°í™”ëœ ìƒì„¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        # ìºì‹œ í‚¤ ìƒì„±
        cache_params = {
            "corp_code": corp_code,
            "rcept_no": rcept_no,
            "api_type": api_type
        }
        
        # ìºì‹œ í™•ì¸
        cached_result = await self.cache.get("_fetch_structured_data", cache_params)
        if cached_result is not None:
            return cached_result
        
        try:
            logger.info(f"[_fetch_structured_data] Fetching {api_type} for {corp_code} / {rcept_no}")
            
            # API íƒ€ì…ë³„ í˜¸ì¶œ - dart_api_toolsì˜ ê³µê°œ í•¨ìˆ˜ ì‚¬ìš©
            data = {}
            year = self._extract_year_from_rcept_no(rcept_no)
            
            if api_type == "periodic_report":
                # ì •ê¸°ë³´ê³ ì„œëŠ” ì‚¬ì—…ë³´ê³ ì„œ íƒ€ì…ìœ¼ë¡œ ì¡°íšŒ
                if detailed_types and detailed_types.get("business_reports"):
                    biz_reports = detailed_types.get("business_reports")
                    
                    # ìƒì„¸ íƒ€ì…ì´ ìˆìœ¼ë©´ ê°ê° ì¡°íšŒ
                    for biz_type in biz_reports:
                        if hasattr(self.dart_api, 'get_business_report_data'):
                            logger.info(f"[_fetch_structured_data] Calling get_business_report_data({corp_code}, {biz_type}, {year})")
                            biz_data = await self.dart_api.get_business_report_data(
                                company=corp_code,
                                business_report_type=biz_type,
                                year=year
                            )
                            
                            if biz_data:
                                parsed = json.loads(biz_data) if isinstance(biz_data, str) else biz_data
                                # rcept_noë¡œ í•„í„°ë§ì´ í•„ìš”í•œ ê²½ìš°
                                if isinstance(parsed, list):
                                    filtered = [item for item in parsed if 
                                              item.get("rcept_no") == rcept_no or 
                                              item.get("rcp_no") == rcept_no]
                                    if filtered:
                                        data[f"business_{biz_type}"] = filtered[0]
                                else:
                                    data[f"business_{biz_type}"] = parsed
                else:
                    # ê¸°ë³¸ ì •ê¸°ë³´ê³ ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    data = await self._fetch_periodic_report_details(corp_code, rcept_no)
                
            elif api_type == "major_report":
                # ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œ - get_major_events ì‚¬ìš©
                if detailed_types and detailed_types.get("major_events"):
                    major_events = detailed_types.get("major_events")
                    
                    for event_type in major_events:
                        if hasattr(self.dart_api, 'get_major_events'):
                            logger.info(f"[_fetch_structured_data] Calling get_major_events({corp_code}, {event_type}, {year})")
                            event_data = await self.dart_api.get_major_events(
                                company=corp_code,
                                event_type=event_type,
                                start_year=str(year)
                            )
                            
                            if event_data:
                                parsed = json.loads(event_data) if isinstance(event_data, str) else event_data
                                
                                # API ì‘ë‹µ ë‚´ìš© í™•ì¸ (ì²˜ìŒ 100ìë§Œ)
                                if isinstance(parsed, dict):
                                    if 'result' in parsed or 'status' in parsed:
                                        logger.warning(f"[_fetch_structured_data] API returned status/result: {parsed.get('result', parsed.get('status'))}")
                                
                                # rcept_noë¡œ í•„í„°ë§
                                if isinstance(parsed, list):
                                    logger.info('qq')
                                    filtered = [item for item in parsed if 
                                              item.get("rcept_no") == rcept_no or 
                                              item.get("rcp_no") == rcept_no]
                                    if filtered:
                                        data[f"event_{event_type}"] = filtered[0]
                                        logger.info(f"[_fetch_structured_data] Found {len(filtered)} matching events for type {event_type}")
                                elif isinstance(parsed, dict) and (
                                    parsed.get("rcept_no") == rcept_no or 
                                    parsed.get("rcp_no") == rcept_no):
                                    data[f"event_{event_type}"] = parsed
                
            elif api_type == "securities_registration":
                # ì¦ê¶Œì‹ ê³ ì„œ - get_securities_report ì‚¬ìš©
                if detailed_types and detailed_types.get("securities"):
                    for sec_type in detailed_types["securities"]:
                        if hasattr(self.dart_api, 'get_securities_report'):
                            sec_data = await self.dart_api.get_securities_report(
                                company=corp_code,
                                securities_type=sec_type,
                                start_year=str(year)
                            )
                            logger.info("[_fetch_structured_data] Calling get_securities_report")
                            if sec_data:
                                parsed = json.loads(sec_data) if isinstance(sec_data, str) else sec_data
                                # rcept_noë¡œ í•„í„°ë§
                                if isinstance(parsed, list):
                                    filtered = [item for item in parsed if 
                                              item.get("rcept_no") == rcept_no or 
                                              item.get("rcp_no") == rcept_no]
                                    if filtered:
                                        logger.info(f"[_fetch_structured_data] Found {len(filtered)} matching securities for type {sec_type}")
                                        data[f"securities_{sec_type}"] = filtered[0]
                                elif isinstance(parsed, dict) and (
                                    parsed.get("rcept_no") == rcept_no or 
                                    parsed.get("rcp_no") == rcept_no):
                                    data[f"securities_{sec_type}"] = parsed
                
            elif api_type == "ownership_disclosure":
                # ì§€ë¶„ê³µì‹œ - get_major_shareholders ì‚¬ìš©
                if hasattr(self.dart_api, 'get_major_shareholders'):
                    shareholders_data = await self.dart_api.get_major_shareholders(corp_code)
                    if shareholders_data:
                        parsed = json.loads(shareholders_data) if isinstance(shareholders_data, str) else shareholders_data
                        # rcept_noë¡œ í•„í„°ë§
                        if isinstance(parsed, list):
                            filtered = [item for item in parsed if 
                                      item.get("rcept_no") == rcept_no or 
                                      item.get("rcp_no") == rcept_no]
                            if filtered:
                                data["major_shareholders"] = filtered[0]
                        else:
                            data["major_shareholders"] = parsed
            else:
                return None
            
            
            if not data:
                logger.info(f"[_fetch_structured_data] âš ï¸ No data collected, returning None")
                return None
                
            # ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì˜¨ ê²½ìš° ìºì‹œì— ì €ì¥
            if data and not data.get("error"):
                await self.cache.set("_fetch_structured_data", cache_params, data)
                logger.info(f"[_fetch_structured_data] âœ… Cached structured data for {rcept_no}, keys: {list(data.keys())}")
            else:
                logger.warning(f"[_fetch_structured_data] âš ï¸ Data contains error, not caching")
                
            return data
            
        except Exception as e:
            logger.error(f"[_fetch_structured_data] ğŸ’¥ Exception occurred: {type(e).__name__}: {e}")
            return {"error": str(e)}
    
    async def _fetch_periodic_report_details(self, corp_code: str, rcept_no: str) -> Dict[str, Any]:
        """ì •ê¸°ë³´ê³ ì„œ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        result = {}
        
        try:
            # ì¬ë¬´ì œí‘œ ì •ë³´
            if hasattr(self.dart_api, 'get_financial_statements'):
                year = self._extract_year_from_rcept_no(rcept_no)
                if year:
                    fs_data = await self.dart_api.get_financial_statements(
                        company=corp_code,
                        year=year,
                        comprehensive=True
                    )
                    if fs_data:
                        result["financial_statements"] = json.loads(fs_data) if isinstance(fs_data, str) else fs_data
            
            # ë°°ë‹¹ ì •ë³´
            if hasattr(self.dart_api, 'get_business_report_data'):
                dividend_data = await self.dart_api.get_business_report_data(
                    company=corp_code,
                    business_report_type="ë°°ë‹¹",
                    year=self._extract_year_from_rcept_no(rcept_no)
                )
                if dividend_data:
                    result["dividend"] = json.loads(dividend_data) if isinstance(dividend_data, str) else dividend_data
            
            return result
            
        except Exception as e:
            logger.error(f"Error fetching periodic report details: {e}")
            return {"error": str(e)}
    
    
    
    
    async def _fetch_original_document(self, rcept_no: str) -> Dict[str, Any]:
        """ì›ë³¸ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° (ì‹¤ì œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ)"""
        # ìºì‹œ í‚¤ ìƒì„±
        cache_params = {
            "rcept_no": rcept_no,
            "document_type": "original"
        }
        
        # ìºì‹œ í™•ì¸
        cached_result = await self.cache.get("_fetch_original_document", cache_params)
        if cached_result is not None:
            logger.debug(f"Cache hit for original document {rcept_no}")
            return cached_result
        
        try:
            # 1. ë¨¼ì € ê°„ë‹¨í•œ ë¬¸ì„œ ì •ë³´ API ì‹œë„
            if hasattr(self.dart_api, 'get_document_content'):
                content_result = await self.dart_api.get_document_content(
                    rcp_no=rcept_no,  # íŒŒë¼ë¯¸í„°ëª… ìˆ˜ì •
                    get_all=False  # ìš”ì•½ë³¸
                )
                
                if isinstance(content_result, str):
                    content_data = json.loads(content_result)
                else:
                    content_data = content_result
                
                # ë‚´ìš©ì´ ì¶©ë¶„íˆ ìˆìœ¼ë©´ ë°˜í™˜ (ì‹¤ì œ ë‚´ìš©ì¸ì§€ í™•ì¸)
                if "error" not in content_data and content_data.get("content"):
                    parsed_content = self._parse_document_content(content_data)
                    # OpenDartReaderì˜ document()ëŠ” ë³´í†µ URLì´ë‚˜ ê°„ë‹¨í•œ ì •ë³´ë§Œ ë°˜í™˜
                    # ì‹¤ì œ ë‚´ìš©ì´ 1000ì ì´ìƒì´ì–´ì•¼ ìœ íš¨í•œ ë¬¸ì„œë¡œ ê°„ì£¼
                    if parsed_content and len(parsed_content) > 1000 and not parsed_content.startswith("http"):
                        # XML/HTML íƒœê·¸ ì •ë¦¬
                        cleaned_content = clean_content(parsed_content, preserve_structure=True)
                        logger.info(f"Using document API content ({len(cleaned_content)} chars after cleaning)")
                        result = {
                            "content": cleaned_content,
                            "raw_data": content_data,
                            "source": "document_api"
                        }
                        # ìºì‹œì— ì €ì¥
                        await self.cache.set("_fetch_original_document", cache_params, result)
                        return result
                    else:
                        logger.info(f"Document API content insufficient ({len(parsed_content) if parsed_content else 0} chars), will download")
            
            # 2. ì‹¤ì œ ì›ë³¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œë„
            logger.info(f"Attempting to download original file for {rcept_no}")
            
            # document_downloader ì„í¬íŠ¸
            from utils.document_downloader import download_dart_document
            import os
            
            api_key = os.getenv("DART_API_KEY")
            if api_key:
                download_result = await download_dart_document(rcept_no, api_key)
                
                if not download_result.get("error"):
                    # ë‹¤ìš´ë¡œë“œ ì„±ê³µ
                    content = download_result.get("main_text") or download_result.get("content")
                    if content:
                        # XML/HTML íƒœê·¸ ì •ë¦¬
                        cleaned_content = clean_content(content, preserve_structure=True)
                        logger.info(f"Successfully downloaded and extracted {len(cleaned_content)} characters after cleaning")
                        result = {
                            "content": cleaned_content,
                            "files": download_result.get("files", []),
                            "source": "downloaded_file"
                        }
                        # ìºì‹œì— ì €ì¥
                        await self.cache.set("_fetch_original_document", cache_params, result)
                        return result
                else:
                    logger.warning(f"Download failed: {download_result['error']}")
            
            # 3. ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ì‹œ URLë§Œ ì œê³µ
            download_url = f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}"
            return {
                "content": None,
                "download_url": download_url,
                "message": "ì›ë³¸ ë¬¸ì„œëŠ” ë‹¤ìš´ë¡œë“œ URLì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤",
                "source": "url_only"
            }
            
        except Exception as e:
            logger.error(f"Error fetching original document: {e}")
            return {"error": str(e)}
    
    def _extract_content_from_structured(self, structured_data: Dict[str, Any]) -> str:
        """êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ (ì´ë¯¸ ë§¤í•‘ëœ ë°ì´í„° ì²˜ë¦¬)"""
        content_parts = []
        
        # ë°ì´í„°ì˜ ëª¨ë“  í‚¤ë¥¼ ìˆœíšŒí•˜ë©´ì„œ ë‚´ìš© ì¶”ì¶œ
        for key, value in structured_data.items():
            if value and key != "error":
                # í‚¤ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
                if key.startswith("business_"):
                    section_name = key.replace("business_", "ì‚¬ì—…ë³´ê³ ì„œ - ")
                elif key.startswith("event_"):
                    section_name = key.replace("event_", "ì£¼ìš”ì‚¬í•­ - ")
                elif key.startswith("securities_"):
                    section_name = key.replace("securities_", "ì¦ê¶Œì‹ ê³  - ")
                elif key == "financial_statements":
                    section_name = "ì¬ë¬´ì œí‘œ"
                elif key == "dividend":
                    section_name = "ë°°ë‹¹ ì •ë³´"
                elif key == "executives":
                    section_name = "ì„ì› ì •ë³´"
                elif key == "total_shares":
                    section_name = "ì£¼ì‹ì´ìˆ˜"
                elif key == "major_shareholders":
                    section_name = "ì£¼ìš”ì£¼ì£¼"
                else:
                    section_name = key
                
                content_parts.append(f"\n=== {section_name} ===")
                
                # ê°’ì˜ íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬ (ì´ë¯¸ ë§¤í•‘ëœ ë°ì´í„°)
                if isinstance(value, dict):
                    # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° í‚¤-ê°’ ìŒìœ¼ë¡œ ì¶œë ¥
                    for sub_key, sub_value in value.items():
                        if sub_value and sub_key not in ["error", "status", "result", "message"]:
                            content_parts.append(f"  â€¢ {sub_key}: {str(sub_value)[:500]}")
                    
                elif isinstance(value, list):
                    # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê° í•­ëª© ì²˜ë¦¬
                    for i, item in enumerate(value[:5], 1):  # ìƒìœ„ 5ê°œë§Œ
                        if isinstance(item, dict):
                            content_parts.append(f"\n  [{i}ë²ˆì§¸ í•­ëª©]")
                            # ì£¼ìš” í•„ë“œë“¤ í‘œì‹œ (ì´ë¯¸ í•œê¸€ë¡œ ë³€í™˜ëœ ìƒíƒœ)
                            important_fields = ['ì ‘ìˆ˜ë²ˆí˜¸', 'íšŒì‚¬ëª…', 'ë³´ê³ ì„œëª…', 'ì ‘ìˆ˜ì¼ì', 
                                              'ë³´ê³ ì‚¬ìœ ', 'ì œì¶œì¸', 'ë¹„ê³ ', 'ì£¼ì£¼ëª…', 'ì„±ëª…', 'ì§ìœ„']
                            for field in important_fields:
                                if field in item and item[field]:
                                    content_parts.append(f"    â€¢ {field}: {item[field]}")
                            
                            # ì¤‘ìš” í•„ë“œê°€ ì—†ìœ¼ë©´ ëª¨ë“  í•„ë“œ í‘œì‹œ
                            if not any(field in item for field in important_fields):
                                for sub_key, sub_value in item.items():
                                    if sub_value and sub_key not in ["error", "status", "result", "message"]:
                                        content_parts.append(f"    â€¢ {sub_key}: {str(sub_value)[:300]}")
                        else:
                            content_parts.append(f"  [{i}] {str(item)[:500]}")
                else:
                    # ê¸°íƒ€ íƒ€ì…
                    content_parts.append(str(value)[:1000])
        
        return "\n".join(content_parts) if content_parts else "êµ¬ì¡°í™”ëœ ë°ì´í„° ì—†ìŒ"
    
    def _parse_document_content(self, doc_data: Any) -> str:
        """ë¬¸ì„œ ë°ì´í„° íŒŒì‹± - XML/HTML íƒœê·¸ ì œê±° ë° êµ¬ì¡°í™”"""
        content = ""
        
        if isinstance(doc_data, str):
            content = doc_data
        elif isinstance(doc_data, dict):
            # content í•„ë“œê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
            if "content" in doc_data:
                content = str(doc_data["content"])
            # DataFrame í˜•íƒœì˜ ë°ì´í„°
            elif "data" in doc_data:
                content = str(doc_data["data"])
            # í…ìŠ¤íŠ¸ í•„ë“œë“¤
            else:
                text_parts = []
                for key in ["text", "body", "document"]:
                    if key in doc_data:
                        text_parts.append(str(doc_data[key]))
                content = "\n".join(text_parts)
        else:
            content = str(doc_data)
        
        # XML íƒœê·¸ ì œê±° ë° ë‚´ìš© ì¶”ì¶œ
        if content and ("<?xml" in content or "<DOCUMENT" in content):
            import re
            
            # ì£¼ìš” ì •ë³´ ì¶”ì¶œì„ ìœ„í•œ íŒ¨í„´
            patterns = {
                "íšŒì‚¬ëª…": r"<COMPANY-NAME[^>]*>([^<]+)</COMPANY-NAME>",
                "ë¬¸ì„œëª…": r"<DOCUMENT-NAME[^>]*>([^<]+)</DOCUMENT-NAME>",
                "ëŒ€í‘œì´ì‚¬": r"<REPRESENTATIVE[^>]*>([^<]+)</REPRESENTATIVE>",
                
                # í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ
                "í•­ëª©ëª…": r"<TH[^>]*>([^<]+)</TH>",
                "í…Œì´ë¸”ë‚´ìš©": r"<TE[^>]*>([^<]+)</TE>",
                "í…Œì´ë¸”ìˆ«ì": r"<TN[^>]*>([^<]+)</TN>",
                "ë‹¨ë½": r"<P[^>]*>([^<]+)</P>",
            }
            
            result = []
            
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            for label, pattern in patterns.items():
                matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
                if matches:
                    # ê³µë°± ì œê±° ë° ì •ë¦¬
                    cleaned_matches = []
                    for match in matches:
                        cleaned = match.strip()
                        cleaned = re.sub(r'\s+', ' ', cleaned)
                        if cleaned and len(cleaned) > 1:  # ë„ˆë¬´ ì§§ì€ ë‚´ìš© ì œì™¸
                            cleaned_matches.append(cleaned)
                    
                    if cleaned_matches:
                        if label in ["íšŒì‚¬ëª…", "ë¬¸ì„œëª…", "ëŒ€í‘œì´ì‚¬"]:
                            # ë©”íƒ€ ì •ë³´ëŠ” ì²« ë²ˆì§¸ë§Œ
                            result.append(f"ã€{label}ã€‘ {cleaned_matches[0]}")
                        else:
                            # í…Œì´ë¸” ë°ì´í„°ëŠ” êµ¬ì¡°í™”
                            result.append(f"\nã€{label}ã€‘")
                            unique_items = list(set(cleaned_matches))[:30]  # ì¤‘ë³µ ì œê±° & ì œí•œ
                            for item in unique_items:
                                if len(item) > 100:  # ê¸´ í…ìŠ¤íŠ¸ëŠ” ë‹¨ë½ìœ¼ë¡œ
                                    result.append(f"\n{item}\n")
                                else:
                                    result.append(f"  â€¢ {item}")
            
            # í…Œì´ë¸” êµ¬ì¡° íŒŒì‹±
            table_pattern = r"<TABLE[^>]*>(.*?)</TABLE>"
            tables = re.findall(table_pattern, content, re.IGNORECASE | re.DOTALL)
            
            if tables:
                result.append("\nã€í…Œì´ë¸” ë°ì´í„°ã€‘")
                for i, table in enumerate(tables[:5], 1):  # ìµœëŒ€ 5ê°œ í…Œì´ë¸”
                    rows = re.findall(r"<TR[^>]*>(.*?)</TR>", table, re.IGNORECASE | re.DOTALL)
                    if rows:
                        result.append(f"\n[í‘œ {i}]")
                        for row in rows[:10]:  # ê° í…Œì´ë¸”ë‹¹ ìµœëŒ€ 10í–‰
                            cells = re.findall(r"<T[DHE][^>]*>([^<]+)</T[DHE]>", row, re.IGNORECASE)
                            if cells:
                                cleaned_cells = [re.sub(r'\s+', ' ', cell.strip()) for cell in cells]
                                cleaned_cells = [c for c in cleaned_cells if c]  # ë¹ˆ ì…€ ì œê±°
                                if cleaned_cells:
                                    result.append("  " + " | ".join(cleaned_cells))
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ (íƒœê·¸ ì œê±°)
            clean_text = re.sub(r'<[^>]+>', ' ', content)
            clean_text = re.sub(r'\s+', ' ', clean_text).strip()
            
            if result:
                final_result = "\n".join(result)
                # ë„ˆë¬´ ì§§ìœ¼ë©´ clean text ì¶”ê°€
                if len(final_result) < 800 and clean_text:
                    final_result += f"\n\nã€ì¶”ê°€ í…ìŠ¤íŠ¸ã€‘\n{clean_text[:2000]}"
                return final_result
            else:
                return clean_text[:5000]
        
        # XMLì´ ì•„ë‹Œ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        return content[:5000] if len(content) > 5000 else content
    
    def _extract_year_from_rcept_no(self, rcept_no: str) -> Optional[int]:
        """ì ‘ìˆ˜ë²ˆí˜¸ì—ì„œ ì—°ë„ ì¶”ì¶œ"""
        try:
            # rcept_no í˜•ì‹: YYYYMMDD...
            if len(rcept_no) >= 4:
                year = int(rcept_no[:4])
                if 2000 <= year <= 2030:
                    return year
        except:
            pass
        return None
    
    async def fetch_multiple_documents(
        self,
        documents: List[Dict[str, Any]],
        max_concurrent: int = 3,
        detailed_types: Dict[str, List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ ë¬¸ì„œ ë™ì‹œ ê°€ì ¸ì˜¤ê¸° (ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜)
        
        Args:
            documents: ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ (rcept_no, corp_code, report_type í¬í•¨)
            max_concurrent: ë™ì‹œ ì²˜ë¦¬ ìˆ˜
            detailed_types: ìƒì„¸ ë¬¸ì„œ íƒ€ì… ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ë¬¸ì„œ ë‚´ìš© ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        # ë°°ì¹˜ ì²˜ë¦¬
        for i in range(0, len(documents), max_concurrent):
            batch = documents[i:i + max_concurrent]
            
            # ë™ì‹œ ì²˜ë¦¬
            tasks = []
            for doc in batch:
                rcept_no = doc.get("rcept_no") or doc.get("rcp_no")
                corp_code = doc.get("corp_code")
                # orchestratorì—ì„œ ì „ë‹¬ëœ report_type ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ì¶”ë¡ 
                report_type = doc.get("report_type") or self._infer_report_type(doc)
                
                tasks.append(
                    self.fetch_document_content(
                        rcept_no=rcept_no,
                        corp_code=corp_code,
                        report_type=report_type,
                        fetch_mode="auto",  # autoë¡œ ë³€ê²½í•˜ì—¬ ì‹¤íŒ¨ì‹œ ì›ë³¸ ë¬¸ì„œë¡œ í´ë°±
                        detailed_types=detailed_types
                    )
                )
            
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for doc, result in zip(batch, batch_results):
                if isinstance(result, Exception):
                    logger.error(f"Failed to fetch {doc.get('rcept_no')}: {result}")
                    results.append({
                        "rcept_no": doc.get("rcept_no"),
                        "content": None,
                        "error": str(result)
                    })
                else:
                    # ì›ë³¸ ë¬¸ì„œ ì •ë³´ì™€ ë³‘í•©
                    result.update({
                        "corp_name": doc.get("corp_name"),
                        "report_nm": doc.get("report_nm"),
                        "rcept_dt": doc.get("rcept_dt")
                    })
                    results.append(result)
        
        return results
    
    def _infer_report_type(self, doc: Dict[str, Any]) -> Optional[str]:
        """ë¬¸ì„œ ì •ë³´ì—ì„œ ë³´ê³ ì„œ ìœ í˜• ì¶”ë¡ """
        report_nm = doc.get("report_nm", "").lower()
        
        # ì •ê¸°ë³´ê³ ì„œ
        if "ì‚¬ì—…ë³´ê³ ì„œ" in report_nm:
            return "A001"
        elif "ë°˜ê¸°ë³´ê³ ì„œ" in report_nm:
            return "A002"
        elif "ë¶„ê¸°ë³´ê³ ì„œ" in report_nm:
            return "A003"
        
        # ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œ
        elif "ì£¼ìš”ì‚¬í•­" in report_nm:
            return "B001"
        elif "ì£¼ìš”ê²½ì˜" in report_nm:
            return "B002"
        
        # ì§€ë¶„ê³µì‹œ
        elif "ëŒ€ëŸ‰ë³´ìœ " in report_nm or "5%" in report_nm:
            return "D001"
        elif "ì„ì›" in report_nm and "ì£¼ì£¼" in report_nm:
            return "D002"
        
        # ì¦ê¶Œì‹ ê³ ì„œ
        elif "ì¦ê¶Œì‹ ê³ " in report_nm:
            if "ì§€ë¶„" in report_nm:
                return "C001"
            elif "ì±„ë¬´" in report_nm or "ì±„ê¶Œ" in report_nm:
                return "C002"
            elif "íŒŒìƒ" in report_nm:
                return "C003"
        
        return None